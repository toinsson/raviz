@article{Belkina2018,
abstract = {Accurate and comprehensive extraction of information from high-dimensional single cell datasets necessitates faithful visualizations to assess biological populations. A state-of-the-art algorithm for non-linear dimension reduction, t-SNE, requires multiple heuristics and fails to produce clear representations of datasets when millions of cells are projected. We developed opt-SNE, an automated toolkit for optimal t-SNE parameter selection that utilizes Kullback-Liebler divergence evaluation in real time to tailor the early exaggeration and overall number of gradient descent iterations in a dataset-specific manner. The precise calibration of early exaggeration together with opt-SNE adjustment of gradient descent learning rate dramatically improves computation time and enables high-quality visualization of large cytometry and transcriptomics datasets, overcoming limitations of analysis tools with hard-coded parameters that often produce poorly resolved or misleading maps of fluorescent and mass cytometry data. In summary, opt-SNE enables optimal data resolution in t-SNE space and more precise data interpretation.},
author = {Belkina, Anna C. and Ciccolella, Christopher O. and Anno, Rina and Halpert, Richard and Spidlen, Josef and Snyder-Cappione, Jennifer E.},
doi = {10.1101/451690},
file = {:Users/antoine/Documents/mendeley{\_}library/Belkina et al/2018/Belkina et al. - 2018 - Automated Optimal Parameters for T-Distributed Stochastic Neighbor Embedding Improve Visualization and Allow Ana.pdf:pdf},
journal = {bioRxiv},
month = {nov},
pages = {451690},
publisher = {Cold Spring Harbor Laboratory},
title = {{Automated Optimal Parameters for T-Distributed Stochastic Neighbor Embedding Improve Visualization and Allow Analysis of Large Datasets}},
url = {https://www.biorxiv.org/content/10.1101/451690v2.abstract},
year = {2018}
}
@inproceedings{Chalmers1996,
abstract = {A technique is presented for the layout of high-dimensional data in a low-dimensional space. This technique builds upon the force-based methods that have been used previously to make visualisations of various types of data such as bibliographies and sets of software modules. The canonical force-based model, related to solutions of the N-body problem, has a computational complexity of 0(N2) per iteration. In this paper is presented a stochastically-based algorithm of linear complexity per iteration which produces good layouts, has low overhead, and is easy to implement. Its performance and accuracy are discussed, in particular with regard to the data to which it is applied. Experience with application to bibliographic and time series data, which may have a dimensionality in the tens of thousands, is described.},
author = {Chalmers and Matthew},
booktitle = {Proc. 7th Conf. Vis. '96},
file = {:Users/antoine/Documents/mendeley{\_}library/Chalmers, Matthew/1996/Chalmers, Matthew - 1996 - A linear iteration time layout algorithm for visualising high-dimensional data.pdf:pdf},
isbn = {0897918649},
keywords = {force-directed placement,high-dimensional data,layout algorithms,spring models,stochastic algorithms,visualization},
pages = {516},
publisher = {Association for Computing Machinery},
title = {{A linear iteration time layout algorithm for visualising high-dimensional data}},
url = {https://dl.acm.org/citation.cfm?id=244979.245035},
year = {1996}
}
@article{Dong2011,
abstract = {K-Nearest Neighbor Graph (K-NNG) construction is an im- portant operation with many web related applications, in- cluding collaborative filtering, similarity search, and many others in data mining and machine learning. Existing meth- ods for K-NNG construction either do not scale, or are spe- cific to certain similarity measures. We present NN-Descent, a simple yet efficient algorithm for approximate K-NNG con- struction with arbitrary similarity measures. Our method is based on local search, has minimal space overhead and does not rely on any shared global index. Hence, it is especially suitable for large-scale applications where data structures need to be distributed over the network. We have shown with a variety of datasets and similarity measures that the proposed method typically converges to above 90{\%} recall with each point comparing only to several percent of the whole dataset on average.},
author = {Dong, Wei and Moses, Charikar and Li, Kai},
doi = {10.1145/1963405.1963487},
file = {:Users/antoine/Documents/mendeley{\_}library/Dong, Moses, Li/2011/Dong, Moses, Li - 2011 - Efficient k-nearest neighbor graph construction for generic similarity measures.pdf:pdf},
isbn = {9781450306324},
keywords = {arbitrary similarity measure,iter-,k -nearest neighbor graph},
pages = {577},
title = {{Efficient k-nearest neighbor graph construction for generic similarity measures}},
year = {2011}
}
@article{Dwyer2009,
abstract = {The adoption of the stress-majorization method from multi-dimensional scaling into graph layout has provided an improved mathematical basis and better convergence properties for so-called “force-directed placement” techniques. In this paper we explore algorithms for augmenting such stress-majorization techniques with simple linear constraints using gradient-projection optimization techniques. Our main focus is a particularly simple class of constraints called “orthogonal-ordering constraints” but we also discuss how gradient-projection methods may be extended to solve more general linear “separation constraints”. In addition, we demonstrate several graph-drawing applications where these types of constraints can be very useful.},
author = {Dwyer, Tim and Koren, Yehuda and Marriott, Kim},
doi = {10.1016/J.DISC.2007.12.103},
file = {:Users/antoine/Documents/mendeley{\_}library/Dwyer, Koren, Marriott/2009/Dwyer, Koren, Marriott - 2009 - Constrained graph layout by stress majorization and gradient projection.pdf:pdf},
issn = {0012-365X},
journal = {Discrete Math.},
month = {apr},
number = {7},
pages = {1895--1908},
publisher = {North-Holland},
title = {{Constrained graph layout by stress majorization and gradient projection}},
url = {https://www.sciencedirect.com/science/article/pii/S0012365X08000083{\#}b16},
volume = {309},
year = {2009}
}
@article{Fruchterman1991,
author = {Fruchterman, Thomas M. J. and Reingold, Edward M.},
doi = {10.1002/spe.4380211102},
file = {:Users/antoine/Documents/mendeley{\_}library/Fruchterman, Reingold/1991/Fruchterman, Reingold - 1991 - Graph drawing by force-directed placement.pdf:pdf},
issn = {00380644},
journal = {Softw. Pract. Exp.},
keywords = {force-directed placement,graph drawing,multi-level techniques,simulated annealing},
month = {nov},
number = {11},
pages = {1129--1164},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Graph drawing by force-directed placement}},
url = {http://doi.wiley.com/10.1002/spe.4380211102},
volume = {21},
year = {1991}
}
@incollection{Gansner2005,
author = {Gansner, Emden R. and Koren, Yehuda and North, Stephen},
doi = {10.1007/978-3-540-31843-9_25},
file = {:Users/antoine/Documents/mendeley{\_}library/Gansner, Koren, North/2005/Gansner, Koren, North - 2005 - Graph Drawing by Stress Majorization.pdf:pdf},
pages = {239--250},
publisher = {Springer, Berlin, Heidelberg},
title = {{Graph Drawing by Stress Majorization}},
url = {http://link.springer.com/10.1007/978-3-540-31843-9{\_}25},
year = {2005}
}
@article{Gove2019,
author = {Gove, R},
doi = {10.1111/cgf.13724},
file = {:Users/antoine/Documents/mendeley{\_}library/Gove/2019/Gove - 2019 - A Random Sampling O ( n ) Force-calculation Algorithm for Graph Layouts.pdf:pdf},
journal = {Eurographics Conf. Vis. 2019},
keywords = {Computer Graphics Forum, EUROGRAPHICS},
number = {3},
title = {{A Random Sampling O ( n ) Force-calculation Algorithm for Graph Layouts}},
volume = {38},
year = {2019}
}
@article{Jacomy2014,
abstract = {Gephi is a network visualization software used in various disciplines (social network analysis, biology, genomics{\ldots}). One of its key features is the ability to display the spatialization process, aiming at transforming the network into a map, and ForceAtlas2 is its default layout algorithm. The latter is developed by the Gephi team as an all-around solution to Gephi users' typical networks (scale-free, 10 to 10,000 nodes). We present here for the first time its functioning and settings. ForceAtlas2 is a force-directed layout close to other algorithms used for network spatialization. We do not claim a theoretical advance but an attempt to integrate different techniques such as the Barnes Hut simulation, degree-dependent repulsive force, and local and global adaptive temperatures. It is designed for the Gephi user experience (it is a continuous algorithm), and we explain which constraints it implies. The algorithm benefits from much feedback and is developed in order to provide many possibilities through its settings. We lay out its complete functioning for the users who need a precise understanding of its behaviour, from the formulas to graphic illustration of the result. We propose a benchmark for our compromise between performance and quality. We also explain why we integrated its various features and discuss our design choices.},
author = {Jacomy, Mathieu and Venturini, Tommaso and Heymann, Sebastien and Bastian, Mathieu},
doi = {10.1371/journal.pone.0098679},
editor = {Muldoon, Mark R.},
file = {:Users/antoine/Documents/mendeley{\_}library/Jacomy et al/2014/Jacomy et al. - 2014 - ForceAtlas2, a Continuous Graph Layout Algorithm for Handy Network Visualization Designed for the Gephi Software.pdf:pdf},
issn = {1932-6203},
journal = {PLoS One},
month = {jun},
number = {6},
pages = {e98679},
publisher = {Public Library of Science},
title = {{ForceAtlas2, a Continuous Graph Layout Algorithm for Handy Network Visualization Designed for the Gephi Software}},
url = {https://dx.plos.org/10.1371/journal.pone.0098679},
volume = {9},
year = {2014}
}
@article{Kobak2018,
abstract = {Single-cell transcriptomics yields ever growing data sets containing RNA expression levels for thousands of genes from up to hundreds of thousands of cells. Common data analysis pipelines include a dimensionality reduction step for visualising the data in two dimensions, most frequently performed using t-distributed stochastic neighbour embedding (t-SNE). It excels at revealing local structure in high-dimensional data, but naive applications often suffer from severe shortcomings, e.g. the global structure of the data is not represented accurately. Here we describe how to circumvent such pitfalls, and explain a protocol for successful exploratory data analysis using t-SNE. They include PCA initialisation, multi-scale similarity kernels, exaggeration, and downsampling-based initialisation for very large data sets. We use published single-cell RNA-seq data sets to demonstrate that this protocol yields superior results compared to the naive application of t-SNE.},
author = {Kobak, Dmitry and Berens, Philipp},
doi = {10.1101/453449},
file = {:Users/antoine/Documents/mendeley{\_}library/Kobak, Berens/2018/Kobak, Berens - 2018 - The art of using t-SNE for single-cell transcriptomics.pdf:pdf},
journal = {bioRxiv},
month = {oct},
pages = {453449},
publisher = {Cold Spring Harbor Laboratory},
title = {{The art of using t-SNE for single-cell transcriptomics}},
url = {https://www.biorxiv.org/content/10.1101/453449v1.full},
year = {2018}
}
@article{Lang2005,
abstract = {In this paper, we work on finding the best method for implementing the KDE in terms of fast computation and memory. We collect results from several type of implementation and compare them with different testing cases: Number of training points, number of dimension, different H's. It turns out that for my type of data, because I have a very small H, the usage of FGT and even IFGT is not recommanded. That leaves me with implementing the Dual Trees.},
author = {Lang, Dustin and Klaas, Mike and de Freitas, N},
file = {:Users/antoine/Documents/mendeley{\_}library/Lang, Klaas, Freitas/2005/Lang, Klaas, Freitas - 2005 - Empirical testing of fast kernel density estimation algorithms.pdf:pdf},
journal = {UBC Tech. Rep.},
pages = {6},
title = {{Empirical testing of fast kernel density estimation algorithms}},
url = {ftp://ftp.cs.ubc.ca/.snapshot/nightly.1/local/techreports/2005/TR-2005-03.pdf},
year = {2005}
}
@article{Linderman2017,
abstract = {t-distributed Stochastic Neighborhood Embedding (t-SNE) is a method for dimensionality reduction and visualization that has become widely popular in recent years. Efficient implementations of t-SNE are available, but they scale poorly to datasets with hundreds of thousands to millions of high dimensional data-points. We present Fast Fourier Transform-accelerated Interpolation-based t-SNE (FIt-SNE), which dramatically accelerates the computation of t-SNE. The most time-consuming step of t-SNE is a convolution that we accelerate by interpolating onto an equispaced grid and subsequently using the fast Fourier transform to perform the convolution. We also optimize the computation of input similarities in high dimensions using multi-threaded approximate nearest neighbors. We further present a modification to t-SNE called "late exaggeration," which allows for easier identification of clusters in t-SNE embeddings. Finally, for datasets that cannot be loaded into the memory, we present out-of-core randomized principal component analysis (oocPCA), so that the top principal components of a dataset can be computed without ever fully loading the matrix, hence allowing for t-SNE of large datasets to be computed on resource-limited machines.},
archivePrefix = {arXiv},
arxivId = {1712.09005},
author = {Linderman, George C. and Rachh, Manas and Hoskins, Jeremy G. and Steinerberger, Stefan and Kluger, Yuval},
doi = {10.1038/s41592-018-0308-4},
eprint = {1712.09005},
file = {:Users/antoine/Documents/mendeley{\_}library/Linderman et al/2017/Linderman et al. - 2017 - Efficient Algorithms for t-distributed Stochastic Neighborhood Embedding.pdf:pdf},
month = {dec},
title = {{Efficient Algorithms for t-distributed Stochastic Neighborhood Embedding}},
url = {http://arxiv.org/abs/1712.09005 http://dx.doi.org/10.1038/s41592-018-0308-4},
year = {2017}
}
@article{Linderman2019,
abstract = {t-distributed stochastic neighborhood embedding (t-SNE), a clustering and visualization method proposed by van der Maaten and Hinton in 2008, has rapidly become a standard tool in a number of natur...},
author = {Linderman, George C. and Steinerberger, Stefan},
doi = {10.1137/18M1216134},
file = {:Users/antoine/Documents/mendeley{\_}library/Linderman, Steinerberger/2019/Linderman, Steinerberger - 2019 - Clustering with t-SNE, Provably.pdf:pdf},
issn = {2577-0187},
journal = {SIAM J. Math. Data Sci.},
keywords = {35K55,60J20,60J60,discrete dynamical system,discrete elliptic equation,maximum principle,spectral clustering,t-SNE,visualization},
month = {jan},
number = {2},
pages = {313--332},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Clustering with t-SNE, Provably}},
url = {https://epubs.siam.org/doi/10.1137/18M1216134},
volume = {1},
year = {2019}
}
@article{Maaten2014,
author = {van der Maaten, Laurens},
file = {:Users/antoine/Documents/mendeley{\_}library/Maaten/2014/Maaten - 2014 - Accelerating t-SNE using Tree-Based Algorithms.pdf:pdf},
journal = {J. Mach. Learn. Res.},
pages = {3221--3245},
title = {{Accelerating t-SNE using Tree-Based Algorithms}},
url = {http://jmlr.org/papers/v15/vandermaaten14a.html},
volume = {15},
year = {2014}
}
@article{Maaten2008,
author = {van der Maaten, Laurens and Hinton, Geoffrey},
file = {:Users/antoine/Documents/mendeley{\_}library/Maaten, Hinton/2008/Maaten, Hinton - 2008 - Visualizing Data using t-SNE.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {J. Mach. Learn. Res.},
number = {Nov},
pages = {2579--2605},
title = {{Visualizing Data using t-SNE}},
url = {http://www.jmlr.org/papers/v9/vandermaaten08a.html},
volume = {9},
year = {2008}
}
@article{Malkov2016,
abstract = {We present a new approach for the approximate K-nearest neighbor search based on navigable small world graphs with controllable hierarchy (Hierarchical NSW, HNSW). The proposed solution is fully graph-based, without any need for additional search structures, which are typically used at the coarse search stage of the most proximity graph techniques. Hierarchical NSW incrementally builds a multi-layer structure consisting from hierarchical set of proximity graphs (layers) for nested subsets of the stored elements. The maximum layer in which an element is present is selected randomly with an exponentially decaying probability distribution. This allows producing graphs similar to the previously studied Navigable Small World (NSW) structures while additionally having the links separated by their characteristic distance scales. Starting search from the upper layer together with utilizing the scale separation boosts the performance compared to NSW and allows a logarithmic complexity scaling. Additional employment of a heuristic for selecting proximity graph neighbors significantly increases performance at high recall and in case of highly clustered data. Performance evaluation has demonstrated that the proposed general metric space search index is able to strongly outperform previous opensource state-of-the-art vector-only approaches. Similarity of the algorithm to the skip list structure allows straightforward balanced distributed implementation.},
archivePrefix = {arXiv},
arxivId = {1603.09320},
author = {Malkov, Yu. A. and Yashunin, D. A.},
eprint = {1603.09320},
file = {:Users/antoine/Documents/mendeley{\_}library/Malkov, Yashunin/2016/Malkov, Yashunin - 2016 - Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs.pdf:pdf},
month = {mar},
title = {{Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs}},
url = {http://arxiv.org/abs/1603.09320},
year = {2016}
}
@inproceedings{Moritz2017,
address = {New York, New York, USA},
author = {Moritz, Dominik and Fisher, Danyel and Ding, Bolin and Wang, Chi},
booktitle = {Proc. 2017 CHI Conf. Hum. Factors Comput. Syst.  - CHI '17},
doi = {10.1145/3025453.3025456},
file = {:Users/antoine/Documents/mendeley{\_}library/Moritz et al/2017/Moritz et al. - 2017 - Trust, but Verify Optimistic Visualizations of Approximate Queries for Exploring Big Data.pdf:pdf},
isbn = {9781450346559},
keywords = {approximation,data visualization,exploratory analysis,optimistic visualization,uncertainty},
pages = {2904--2915},
publisher = {ACM Press},
title = {{Trust, but Verify: Optimistic Visualizations of Approximate Queries for Exploring Big Data}},
url = {http://dl.acm.org/citation.cfm?doid=3025453.3025456},
year = {2017}
}
@article{Morrison2004,
abstract = {The problem of exploring or visualising data of high dimensionality is central to many tools for information visualisation. Through representing a data set in terms of inter-object proximities, multidimensional scaling may be employed to generate a configuration of objects in low-dimensional space in such a way as to preserve high-dimensional relationships. An algorithm is presented here for a heuristic hybrid model for the generation of such configurations. Building on a model introduced in 2002, the algorithm functions by means of sampling, spring model and interpolation phases. The most computationally complex stage of the original algorithm involved the execution of a series of nearest-neighbour searches. In this paper, we describe how the complexity of this phase has been reduced by treating all high-dimensional relationships as a set of discretised distances to a constant number of randomly selected items: pivots. In improving this computational bottle-neck, the algorithmic complexity is reduced fro...},
author = {Morrison, Alistair and Chalmers, Matthew},
doi = {10.1057/palgrave.ivs.9500069},
file = {:Users/antoine/Documents/mendeley{\_}library/Morrison, Chalmers/2004/Morrison, Chalmers - 2004 - A Pivot-Based Routine for Improved Parent-Finding in Hybrid MDS.pdf:pdf},
issn = {1473-8716},
journal = {Inf. Vis.},
keywords = {MDS,force-directed placement,hybrid algorithms,multidimensional scaling,near-neighbour search,pivots,spring models},
month = {jun},
number = {2},
pages = {109--122},
publisher = {SAGE PublicationsSage UK: London, England},
title = {{A Pivot-Based Routine for Improved Parent-Finding in Hybrid MDS}},
url = {http://journals.sagepub.com/doi/10.1057/palgrave.ivs.9500069},
volume = {3},
year = {2004}
}
@article{Morrison2003,
abstract = {The term ‘proximity data' refers to data sets within which it is possible to assess the similarity of pairs of objects. Multidimensional scaling (MDS) is applied to such data and attempts to map high-dimensional objects onto low-dimensional space through the preservation of these similarity relations. Standard MDS techniques have in the past suffered from high computational complexity and, as such, could not feasibly be applied to data sets over a few thousand objects in size. Through a novel hybrid approach based upon stochastic sampling, interpolation and spring models, we have designed an algorithm running in O(N√N). Using Chalmers' 1996 O(N2) spring model as a benchmark for the evaluation of our technique, we compare layout quality and run times using sets of synthetic and real data. Our algorithm executes significantly faster than Chalmers' 1996 algorithm, while producing superior layouts. In reducing complexity and run time, we allow the visualisation of data sets of previously infeasible size. Our ...},
author = {Morrison, Alistair and Ross, Greg and Chalmers, Matthew},
doi = {10.1057/palgrave.ivs.9500040},
file = {:Users/antoine/Documents/mendeley{\_}library/Morrison, Ross, Chalmers/2003/Morrison, Ross, Chalmers - 2003 - Fast Multidimensional Scaling Through Sampling, Springs and Interpolation.pdf:pdf},
issn = {1473-8716},
journal = {Inf. Vis.},
keywords = {Multidimensional scaling,hybrid algorithms,spring models},
month = {mar},
number = {1},
pages = {68--77},
publisher = {SAGE PublicationsSage UK: London, England},
title = {{Fast Multidimensional Scaling Through Sampling, Springs and Interpolation}},
url = {http://journals.sagepub.com/doi/10.1057/palgrave.ivs.9500040},
volume = {2},
year = {2003}
}
@article{Pezzotti2016,
author = {Pezzotti, N. and H{\"{o}}llt, T. and Lelieveldt, B. and Eisemann, E. and Vilanova, A.},
doi = {10.1111/cgf.12878},
file = {:Users/antoine/Documents/mendeley{\_}library/Pezzotti et al/2016/Pezzotti et al. - 2016 - Hierarchical Stochastic Neighbor Embedding.pdf:pdf},
issn = {01677055},
journal = {Comput. Graph. Forum},
keywords = {Categories and Subject Descriptors (according to ACM CCS),I.3.0 [Computer Graphics]: General},
month = {jun},
number = {3},
pages = {21--30},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{Hierarchical Stochastic Neighbor Embedding}},
url = {http://doi.wiley.com/10.1111/cgf.12878},
volume = {35},
year = {2016}
}
@article{Pezzotti2017,
author = {Pezzotti, Nicola and Lelieveldt, Boudewijn P. F. and van der Maaten, Laurens and Hollt, Thomas and Eisemann, Elmar and Vilanova, Anna},
doi = {10.1109/TVCG.2016.2570755},
file = {:Users/antoine/Documents/mendeley{\_}library/Pezzotti et al/2017/Pezzotti et al. - 2017 - Approximated and User Steerable tSNE for Progressive Visual Analytics.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Trans. Vis. Comput. Graph.},
month = {jul},
number = {7},
pages = {1739--1752},
title = {{Approximated and User Steerable tSNE for Progressive Visual Analytics}},
url = {http://ieeexplore.ieee.org/document/7473883/},
volume = {23},
year = {2017}
}
@article{Pezzotti2015,
abstract = {Progressive Visual Analytics aims at improving the interactivity in existing analytics techniques by means of visualization as well as interaction with intermediate results. One key method for data analysis is dimensionality reduction, for example, to produce 2D embeddings that can be visualized and analyzed efficiently. t-Distributed Stochastic Neighbor Embedding (tSNE) is a well-suited technique for the visualization of several high-dimensional data. tSNE can create meaningful intermediate results but suffers from a slow initialization that constrains its application in Progressive Visual Analytics. We introduce a controllable tSNE approximation (A-tSNE), which trades off speed and accuracy, to enable interactive data exploration. We offer real-time visualization techniques, including a density-based solution and a Magic Lens to inspect the degree of approximation. With this feedback, the user can decide on local refinements and steer the approximation level during the analysis. We demonstrate our technique with several datasets, in a real-world research scenario and for the real-time analysis of high-dimensional streams to illustrate its effectiveness for interactive data analysis.},
archivePrefix = {arXiv},
arxivId = {1512.01655},
author = {Pezzotti, Nicola and Lelieveldt, Boudewijn P. F. and van der Maaten, Laurens and H{\"{o}}llt, Thomas and Eisemann, Elmar and Vilanova, Anna},
eprint = {1512.01655},
file = {:Users/antoine/Documents/mendeley{\_}library/Pezzotti et al/2015/Pezzotti et al. - 2015 - Approximated and User Steerable tSNE for Progressive Visual Analytics.pdf:pdf},
month = {dec},
title = {{Approximated and User Steerable tSNE for Progressive Visual Analytics}},
url = {http://arxiv.org/abs/1512.01655},
year = {2015}
}
@article{Pezzotti2018,
abstract = {The t-distributed Stochastic Neighbor Embedding (tSNE) algorithm has become in recent years one of the most used and insightful techniques for the exploratory data analysis of high-dimensional data. tSNE reveals clusters of high-dimensional data points at different scales while it requires only minimal tuning of its parameters. Despite these advantages, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of tSNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the tSNE embedding for large datasets. In this work, we present a novel approach to the minimization of the tSNE objective function that heavily relies on modern graphics hardware and has linear computational complexity. Our technique does not only beat the state of the art, but can even be executed on the client side in a browser. We propose to approximate the repulsion forces between data points using adaptive-resolution textures that are drawn at every iteration with WebGL. This approximation allows us to reformulate the tSNE minimization problem as a series of tensor operation that are computed with TensorFlow.js, a JavaScript library for scalable tensor computations.},
archivePrefix = {arXiv},
arxivId = {1805.10817},
author = {Pezzotti, Nicola and Mordvintsev, Alexander and Hollt, Thomas and Lelieveldt, Boudewijn P. F. and Eisemann, Elmar and Vilanova, Anna},
eprint = {1805.10817},
file = {:Users/antoine/Documents/mendeley{\_}library/Pezzotti et al/2018/Pezzotti et al. - 2018 - Linear tSNE optimization for the Web.pdf:pdf},
month = {may},
title = {{Linear tSNE optimization for the Web}},
url = {http://arxiv.org/abs/1805.10817},
year = {2018}
}
@inproceedings{Theron2018,
address = {New York, New York, USA},
author = {Ther{\'{o}}n, Roberto and Losada, Antonio G. and Benito, Alejandro and Santamar{\'{i}}a, Rodrigo},
booktitle = {Proc. Sixth Int. Conf. Technol. Ecosyst. Enhancing Multicult.  - TEEM'18},
doi = {10.1145/3284179.3284323},
file = {:Users/antoine/Documents/mendeley{\_}library/Ther{\'{o}}n et al/2018/Ther{\'{o}}n et al. - 2018 - Toward supporting decision-making under uncertainty in digital humanities with progressive visualization.pdf:pdf},
isbn = {9781450365185},
keywords = {Decision-making,data provenance,digital humanities,progressive visualization,uncertainty},
pages = {826--832},
publisher = {ACM Press},
title = {{Toward supporting decision-making under uncertainty in digital humanities with progressive visualization}},
url = {http://dl.acm.org/citation.cfm?doid=3284179.3284323},
year = {2018}
}
@article{ToghiEshghi2019,
abstract = {Dimensionality reduction using the t-Distributed Stochastic Neighbor Embedding (t-SNE) algorithm has emerged as a popular tool for visualizing high-parameter single-cell data. While this approach has obvious potential for data visualization it remains unclear how t-SNE analysis compares to conventional manual hand-gating in stratifying and quantitating the frequency of diverse immune cell populations. We applied a comprehensive 38-parameter mass cytometry panel to human blood and compared the frequencies of 28 immune cell subsets using both conventional bivariate and t-SNE-guided manual gating. t-SNE analysis was capable of stratifying every general cellular lineage and most sub-lineages with high correlation between conventional and t-SNE guided cell frequency calculations. However, specific immune cell subsets delineated by the manual gating of continuous variables were not fully separated in t-SNE space thus causing discrepancies in subset identification and quantification between these analytical approaches. Overall, these studies highlight the consistency between t-SNE and conventional hand-gating in stratifying general immune cell lineages while demonstrating that particular cell subsets defined by conventional manual gating may be intermingled in t-SNE space.},
author = {{Toghi Eshghi}, Shadi and Au-Yeung, Amelia and Takahashi, Chikara and Bolen, Christopher R. and Nyachienga, Maclean N. and Lear, Sean P. and Green, Cherie and Mathews, W. Rodney and O'Gorman, William E.},
doi = {10.3389/fimmu.2019.01194},
file = {:Users/antoine/Documents/mendeley{\_}library/Toghi Eshghi et al/2019/Toghi Eshghi et al. - 2019 - Quantitative Comparison of Conventional and t-SNE-guided Gating Analyses.pdf:pdf},
issn = {1664-3224},
journal = {Front. Immunol.},
keywords = {Cytometry Informatics,Hi Dimensional Cytometry,Immunophenotyping,cyTOF,dimensionality reduction,t-SNE},
month = {jun},
pages = {1194},
publisher = {Frontiers},
title = {{Quantitative Comparison of Conventional and t-SNE-guided Gating Analyses}},
url = {https://www.frontiersin.org/article/10.3389/fimmu.2019.01194/full},
volume = {10},
year = {2019}
}
@article{Zheng2018,
abstract = {A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.},
author = {Zheng, Jonathan Xiang Sheng and Pawar, Samraat and Goodman, Dan Francis Matthew},
doi = {10.1109/TVCG.2018.2859997},
file = {:Users/antoine/Documents/mendeley{\_}library/Zheng, Pawar, Goodman/2018/Zheng, Pawar, Goodman - 2018 - Graph Drawing by Stochastic Gradient Descent.pdf:pdf},
issn = {19410506},
journal = {IEEE Trans. Vis. Comput. Graph.},
keywords = {Annealing,Approximation algorithms,Graph drawing,Layout,Mathematical model,Schedules,Standards,Stress,constraints,multidimensional scaling,relaxation,stochastic gradient descent},
pages = {1--1},
title = {{Graph Drawing by Stochastic Gradient Descent}},
url = {https://ieeexplore.ieee.org/document/8419285/},
year = {2018}
}
@article{Zrihem2016,
abstract = {Deep Reinforcement Learning (DRL) is a trending field of research, showing great promise in many challenging problems such as playing Atari, solving Go and controlling robots. While DRL agents perform well in practice we are still missing the tools to analayze their performance and visualize the temporal abstractions that they learn. In this paper, we present a novel method that automatically discovers an internal Semi Markov Decision Process (SMDP) model in the Deep Q Network's (DQN) learned representation. We suggest a novel visualization method that represents the SMDP model by a directed graph and visualize it above a t-SNE map. We show how can we interpret the agent's policy and give evidence for the hierarchical state aggregation that DQNs are learning automatically. Our algorithm is fully automatic, does not require any domain specific knowledge and is evaluated by a novel likelihood based evaluation criteria.},
archivePrefix = {arXiv},
arxivId = {1606.07112},
author = {Zrihem, Nir Ben and Zahavy, Tom and Mannor, Shie},
eprint = {1606.07112},
file = {:Users/antoine/Documents/mendeley{\_}library/Zrihem, Zahavy, Mannor/2016/Zrihem, Zahavy, Mannor - 2016 - Visualizing Dynamics from t-SNE to SEMI-MDPs.pdf:pdf},
month = {jun},
title = {{Visualizing Dynamics: from t-SNE to SEMI-MDPs}},
url = {http://arxiv.org/abs/1606.07112},
year = {2016}
}
