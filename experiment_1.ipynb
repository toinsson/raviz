{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Force layout\n",
    "\n",
    "There exists different python package for force layout based techniques.\n",
    "\n",
    "The two I tried were: \n",
    "- https://github.com/Iain530/force-directed-layout-algorithms\n",
    "- https://github.com/bhargavchippada/forceatlas2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force layout\n",
    "\n",
    "The expression for the stress to optimise is: $stress(X) = \\sum_{i<j}w_{ij}(||X_i - X_j|| - d_{ij})^2$ with $w_{ij} = d_{ij}^{-2}$, $||X_i - X_j||$ the euclidean norm computed in the low-dimensional embedding and $d_{ij}$ representing the pairwise distance in the high-dimensional embedding.\n",
    "\n",
    "The gradient for this cost has an analytical solution equal to:\n",
    "\n",
    "$grad_i(stress(X_i)) = \\sum_j 4 w_{ij} \\frac{(X_i - X_j)}{||X_i - X_j||} (||X_i - X_j|| - d_{ij})$\n",
    "\n",
    "This expression can be computed in different ways. An explicit way does implement the computation for the gradient of the stress:\n",
    "\n",
    "```python\n",
    "def force(self):\n",
    "    # hd_ij, ld_ij: pairwise distances in high, low dimensional space resp.\n",
    "\n",
    "    pdist = ss.distance.pdist(self, 'euclidean')\n",
    "    ld_ij_2 = ss.distance.squareform(pdist)\n",
    "\n",
    "    F_ij_2 = (ld_ij_2 - self.hd_ij) / (ld_ij_2 + EPSILON)\n",
    "    F_ij = F_ij_2[:,:] * self.inv_hd_ij_2\n",
    "\n",
    "    a = self[:, None, :]\n",
    "    ld_ij_1 = (a - a.swapaxes(0,1))\n",
    "\n",
    "    F_ij = F_ij[:,:,None] * ld_ij_1\n",
    "\n",
    "    F_i = np.sum(F_ij, axis=1)\n",
    "\n",
    "    return 4*F_i\n",
    "```\n",
    "\n",
    "It is also possible to use autograd to compute the gradient of a given cost:\n",
    "\n",
    "\n",
    "```python\n",
    "def stress(X):\n",
    "    X = X[:, None, :]\n",
    "    ld_ij_2 = np.sqrt(np.sum(((X - X.swapaxes(0,1))**2), axis=2) + EPSILON)\n",
    "    res = np.sum((ld_ij_2 - hd_ij)**2 * inv_hd_ij_2)\n",
    "    return res\n",
    "\n",
    "gradient = grad(stress)\n",
    "```\n",
    "\n",
    "Similar to a N-body simulation, an optimisation can take place in which the gradient descent is used.\n",
    "\n",
    "```python\n",
    "def gd(grad, x, callback=None, num_iters=200):\n",
    "    for i in range(num_iters):\n",
    "        g = grad()\n",
    "        x -= g/2  # if full gradient, optimisation is unstable\n",
    "    return x\n",
    "\n",
    "def sgd(grad, x, callback=None, num_iters=200, step_size=0.1, mass=0.9):\n",
    "    velocity = np.zeros(x.shape)\n",
    "    for i in range(num_iters):\n",
    "        g = grad()\n",
    "        if callback: callback(x, i, g)\n",
    "        velocity = mass * velocity - (1.0 - mass) * g\n",
    "        x += step_size * velocity\n",
    "    return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
